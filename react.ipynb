{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%!pip -q install langchain-core langchain-community langgraph langchain-openai duckduckgo-search yfinance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Traditional ReAct Prompt"
   ],
   "metadata": {
    "id": "o0vQNgwBKU0n"
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "react_prompt = \"\"\"Assistant is a large language model trained by Microsoft.\n",
    "\n",
    "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
    "\n",
    "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
    "\n",
    "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
    "\n",
    "TOOLS:\n",
    "------\n",
    "\n",
    "Assistant has access to the following tools:\n",
    "\n",
    "wikipedia_search - searches the wikipedia database for the answer\\n\n",
    "web_search - searches the web for the answer\\n\n",
    "calculator - calculates the answer to the question\\n\n",
    "weather_api - gets the weather for the location\\n\n",
    "\n",
    "\n",
    "To use a tool, please use the following format:\n",
    "\n",
    "```\n",
    "Thought: Do I need to use a tool? Yes\n",
    "Action: the action to take, should be one of [wikipedia_search, web_search, calculator, weather_api]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "```\n",
    "\n",
    "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
    "\n",
    "```\n",
    "Thought: Do I need to use a tool? No\n",
    "Final Answer: [your response here]\n",
    "```\n",
    "\n",
    "Begin!\n",
    "\n",
    "\n",
    "New input: Whow was King Arthur?\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple ReAct Agent Design\n",
    "\n",
    "![react diagram](images/react-diagram.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ],
   "metadata": {
    "id": "Iv9zB6BrhbRY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tools"
   ],
   "metadata": {
    "id": "Xjw2pzHJmgcz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# search tools\n",
    "from custom_tools import add, multiply, divide\n",
    "from langchain_community.tools import TavilySearchResults, DuckDuckGoSearchRun\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "search = TavilySearchResults(max_results=2)\n",
    "# search = DuckDuckGoSearchRun()\n",
    "tools = [add, multiply, divide, search]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "id": "1VfRa-pdmm1u",
    "outputId": "c3ded11d-3447-4ad8-a736-44a2cb733895"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "search.invoke(\"How old is Brad Pitt?\")"
   ],
   "metadata": {
    "id": "7rlu8MF-ho6e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Nodes"
   ],
   "metadata": {
    "id": "H7z8wrV9550D"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with using search and performing arithmetic on a set of inputs.\"\n",
    "                                \"Provide your reasoning in an explicit `Thought` section before providing your response.\")\n",
    "\n",
    "# Node\n",
    "def reasoner(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n"
   ],
   "metadata": {
    "id": "uJ6mJ1Hcio3U"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Building the graph"
   ],
   "metadata": {
    "id": "E5T9K_c1nNCP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"reasoner\", reasoner)\n",
    "builder.add_node(\"tools\", ToolNode(tools)) # for the tools\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START, \"reasoner\")\n",
    "builder.add_conditional_edges(\n",
    "    \"reasoner\",\n",
    "    # If the latest message (result) from node reasoner is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from node reasoner is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"reasoner\")\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# Display the graph\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "o0FIm4j0io5S",
    "outputId": "65cc7df0-cef4-4b5e-deb7-41b01eb17be3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "messages = [HumanMessage(content=\"What is 2 times Brad Pitt's age?\")]\n",
    "messages = react_graph.invoke({\"messages\": messages})"
   ],
   "metadata": {
    "id": "yYz5Wc9dio76"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GvzaROdwi64G",
    "outputId": "3b549b46-08ed-446e-e28f-8c92c9f0128d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## More manual way and adding a custom tool"
   ],
   "metadata": {
    "id": "QtczHZq39HKG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from custom_tools import get_stock_price\n",
    "get_stock_price.invoke(\"TSLA\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvJ113s9Ljgq",
    "outputId": "8aaa51ed-bbf0-413d-c642-e56170ea69e5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tools = [add, multiply, divide, search, get_stock_price]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ],
   "metadata": {
    "id": "LBGXfOroEEVD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from typing import Annotated, TypedDict, List\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"State of the graph.\"\"\"\n",
    "    query: str\n",
    "    prices: list[str]\n",
    "    final_answer: str\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n"
   ],
   "metadata": {
    "id": "RH1ap_Yuztf5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Node\n",
    "def reasoner(state):\n",
    "    messages = state[\"messages\"]\n",
    "    # System message\n",
    "    sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with using search, the yahoo finance tool and performing arithmetic on a set of inputs.\")\n",
    "    original_query = HumanMessage(content=state[\"query\"])\n",
    "    messages.append(original_query)\n",
    "    result = [llm_with_tools.invoke([sys_msg] + messages)]\n",
    "    return {\"messages\": result}\n"
   ],
   "metadata": {
    "id": "6-unsLIxCKOq"
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition # this is the checker for the\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "# Graph\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add Nodes\n",
    "workflow.add_node(\"reasoner\", reasoner)\n",
    "workflow.add_node(\"tools\", ToolNode(tools)) # for the tools\n",
    "\n",
    "# Add Edges\n",
    "workflow.add_edge(START, \"reasoner\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"reasoner\",\n",
    "    # If the latest message (result) from node reasoner is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from node reasoner is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"reasoner\")\n",
    "react_graph = workflow.compile()\n",
    "\n",
    "# Show\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "1REv0ndD_Awn",
    "outputId": "9a0edd3f-96c7-4b20-8120-8ff108f10827"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "response = react_graph.invoke({\"query\": \"What is 2 times the stock price of the company that Jensen Huang is CEO of?\", \"messages\": []})"
   ],
   "metadata": {
    "id": "c21ouY0PIQh-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "szgNFSrzJQ0o",
    "outputId": "503e24f7-706d-49dd-99f9-b1d693c4c369"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
